<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<title>RankMixup: Ranking-Based Mixup Training for Network Calibration</title>
	<meta name="author" content="CV-lab">

	<link href="./RankMixup_files/bootstrap.min.css" rel="stylesheet">
    <link href="./RankMixup_files/style.css" rel="stylesheet">
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
  });
  </script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
</head>

  <body>

    <div class="container">
      <div class="header">
        <div style="font-size: 28px">
        <h1> <center> RankMixup: Ranking-Based Mixup Training <br>for Network Calibration </center> </h1>
        <h4 style="color: #517CB9; font-size: 20px"> <center> <a href="https://iccv2023.thecvf.com/"><b>*ICCV 2023*</b></a> </center></center></h4>
        </div>
      </div>

      
      <p style="text-align: justify;">
      <div style="font-size: 14px">
        <img src="./RankMixup_files/teaser.png" style="width:80%; height:80%;" class="center"> 
      </p>  
      <div>
      
        Motivation of RankMixup. 
        We show raw samples of a cat and dog in red boxes, and mixup-augmented samples in blue boxes with dashed lines. The mixup-augmented samples are generated by linearly interpolating the raw samples with a mixing coefficient $\lambda$. We expect that confidences of the raw samples to be higher than that of the augmented sample (top). The augmented samples with larger coefficients $\lambda$ would have higher confidences than the samples with smaller coefficients (bottom).
        </p>
        </div>

      <div class="row">
      	<h3>Authors</h3>
      	<div style="font-size: 16px">
      	<ul>
            <li><a href="https://github.com/njyoun">Jongyoun Noh</a></li>
            <li><a href="https://github.com/HyekangPark">Hyekang Park</a></li>
            <li><a href="https://junghyup-lee.github.io/">Junghyup Lee</a></li>
            <li><a href="https://cvlab.yonsei.ac.kr/">Bumsub Ham</a></li>
      	</ul>
      	</div>
        

      </div>

      <div class="row">
        <h3>Abstract</h3>
        <p style="text-align: justify;">
          Network calibration aims to accurately estimate the level of confidences, which is particularly important for employing deep neural networks in real-world systems. Recent approaches leverage mixup to calibrate the network's predictions during training. However, they do not consider the problem that mixtures of labels in mixup may not accurately represent the actual distribution of augmented samples. In this paper, we present RankMixup, a novel mixup-based framework alleviating the problem of the mixture of labels for network calibration. To this end, we propose to use an ordinal ranking relationship between raw and mixup-augmented samples as an alternative supervisory signal to the label mixtures for network calibration. We hypothesize that the network should estimate a higher level of confidence for the raw samples than the augmented ones (Figure). To implement this idea, we introduce a mixup-based ranking loss (MRL) that encourages lower confidences for augmented samples compared to raw ones, maintaining the ranking relationship. We also propose to leverage the ranking relationship among multiple mixup-augmented samples to further improve the calibration capability. Augmented samples with larger mixing coefficients are expected to have higher confidences and vice versa (Figure). That is, the order of confidences should be aligned with that of mixing coefficients. To this end, we introduce a novel loss, M-NDCG, in order to reduce the number of misaligned pairs of the coefficients and confidences. Extensive experimental results on standard benchmarks for network calibration demonstrate the effectiveness of RankMixup.

        </p>  
        <div style="font-size: 14px">
        <p style="text-align: justify;">
        <!-- <br>
        <img src="./RankMixup_files/teaser.png" class="center" style="max-width:55%;;padding-right:20px;">
        <br> -->
        
      <div class="row">
      	<h3>Results</h3>
        <p style="text-align: justify;">
        <img src="./RankMixup_files/result.png" style="width:100%; height:100%;" class="center">
        </p>
      <div>
      <p style="text-align: justify;">
        Quantitative comparison with the state of the art in terms of ECE (%) and AECE (%) with 15 bins on the validation splits of CIFAR10/100 and Tiny-ImageNet. Numbers in bold indicate the best performance and underscored ones indicate the second best. Numbers in parentheses represent the results obtained using a TS post-hoc technique.
       </p>
       </div>
      </div>

      <div class="row">
        <h3>Paper</h3>
	<p>
     </p><table>
  <tbody><tr></tr>
  <tr><td>
    <a href="https://arxiv.org/"><img style="box-shadow: 5px 5px 2px #888888; margin: 10px" src="./RankMixup_files/thb.png" width="150px"></a>
  </td>
  <td></td>
  <td>
    J. Noh, H. Park, J. Lee, B. Ham<br>
    <b>RankMixup: Ranking-Based Mixup Training for Network Calibration</b> <br>
    In <i>Proceedings of the IEEE/CVF Internatioanl Conference on Computer Vision (ICCV) </i>, 2023 <br>
    [<a href="https://arxiv.org/">Paper on arXiv</a>] [<a href="https://github.com/njyoun">Code will be released soon</a>]
</td></tr></tbody></table>
     
      <h3>BibTeX</h3>
     <pre><tt>
	</tt></pre>
      
      <div class="row">
        <h3>Acknowledgements</h3>
        <p>
          This work was supported in part by the NRF and IITP grants funded by the Korea government (MSIT) (No.2023R1A2C2004306, No.2022-0-00124, Development of Artificial Intelligence Technology for Self-Improving Competency-Aware Learning Capabilities, No.2021-0-02068, Artificial Intelligence Innovation Hub), and the Yonsei Signature Research Cluster Program of 2023 (2023-22-0008).
        
		</p>
      </div>

    </div>
