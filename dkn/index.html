<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<title>Deformable Kernel Networks for Joint Image Filtering</title>
	<meta name="author" content="SLV-lab">

	<link href="./css/bootstrap.min.css" rel="stylesheet">
    <link href="./css/style.css" rel="stylesheet">

</head>

  <body>

    <div class="container">
      <div class="header">
        <h3> <center>Deformable Kernel Networks for Joint Image Filtering</center> </h3>
      </div>

      <center>
        <img src="./images/teaser.png" style="max-width:100%;">
      </center>
      <p><strong>Fig.</strong> Qualitative comparison of the state of the art and our model on depth map upsampling (16×). Given a high-resolution color image and a low-resolution depth image from the Sintel dataset, we upsample the depth image using GF, SDF, DJFR and our method.</p>

      <div class="row">
      	<h3>Authors</h3>
      	<div style="font-size: 16px">
      	<ul>
            <li><a href="https://github.com/jun0kim">Beomjun Kim</a></li>
            <li><a href="https://www.di.ens.fr/~ponce/">Jean Ponce</a></li>
            <li><a href="https://bsham.github.io/">Bumsub Ham</a></li>
      	</ul>
      	</div>

      </div>

      <div class="row">
        <h3>Abstract</h3>
        <p style="text-align: justify;">
          Joint image filters are used to transfer structural details from a guidance picture used as a prior to a target image, in tasks such as enhancing spatial resolution and suppressing noise. Previous methods based on convolutional neural networks (CNNs) combine nonlinear activations of spatially-invariant kernels to estimate structural details and regress the filtering result. In this paper, we instead learn explicitly sparse and spatially-variant kernels. We propose a CNN architecture and its efficient implementation, called the deformable kernel network (DKN), that outputs sets of neighbors and the corresponding weights adaptively for each pixel. The filtering result is then computed as a weighted average. We also propose a fast version of DKN that runs about seventeen times faster for an image of size 640 × 480. We demonstrate the effectiveness and flexibility of our models on the tasks of depth map upsampling, saliency map upsampling, cross-modality image restoration, texture removal, and semantic segmentation. In particular, we show that the weighted averaging process with sparsely sampled 3 × 3 kernels outperforms the state of the art by a significant margin in all cases.
        </p>
      </div>
      <div class="row">
      	<h3>Overview of our architecture</h3>
      	<center>
        <img src="./images/arch.png" style="max-width:90%;">
      	</center>
      </div>

      <div class="row">
        <h3>Results</h3>

        <center style="margin-bottom:20px;">
          <img src="images/qual.png" style="max-width:80%;">
          <p>
            <strong>Fig.</strong> Visual comparison of upsampled depth maps (8×).
          </p>
        </center>

      </div>
        <center>
          <div style="max-width:80%;">
          <img src="images/quan.png" style="max-width:100%;">
          <p> <strong>Table.</strong> Quantitive comparison with the state of the art on depth map upsampling in terms of average RMSE. </p>
        </div>
        </center>




      <div class="row">
        <h3>Paper</h3>
	<p>
     </p><table>
  <tbody><tr></tr>
  <tr><td>
    <a href=""><img style="box-shadow: 5px 5px 2px #888888; margin: 10px" src="./images/dkn.png" width="150px"></a>
  </td>
  <td></td>
  <td>
    B. Kim, J. Ponce, B. Ham<br>
    <b>Deformable Kernel Networks for Joint Image Filtering</b> <br>
    [<a href="https://arxiv.org/abs/1910.08373">Paper</a>] [<a href="https://github.com/cvlab-yonsei/projects/tree/master/dkn/code">Code</a>]
</td></tr></tbody></table>
     
      <!-- <h3>BibTeX</h3>
     <pre><tt></tt></pre> -->

      </div>

      
      
      <div class="row">
        <h3>Acknowledgements</h3>
        <p>
        TBD
        
		</p>
      </div>

    </div>
