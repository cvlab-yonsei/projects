<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	
	<title>Deformable kernel networks for guided depth map upsampling</title>
	<meta name="author" content="SLV-lab">

	<link href="./css/bootstrap.min.css" rel="stylesheet">
    <link href="./css/style.css" rel="stylesheet">

</head>

  <body>

    <div class="container">
      <div class="header">
        <h3> <center> Deformable kernel networks for guided depth map upsampling </center> </h3>
      </div>

      <center>
        <img src="./images/teaser.png" style="max-width:100%;">
      </center>
      <p>Fig. Qualitative comparison of the state of the art and our model on depth map upsampling (16×). Given a high-resolution color image and a low-resolution depth image from the Sintel dataset, we upsample the depth image using GF, SDF, DJFR and our method.</p>

      <div class="row">
      	<h3>Authors</h3>
      	<div style="font-size: 16px">
      	<ul>
            <li><a href="https://github.com/jun0kim">Beomjun Kim</a></li>
            <li><a href="https://www.di.ens.fr/~ponce/">Jean Ponce</a></li>
            <li><a href="https://bsham.github.io/">Bumsub Ham</a></li>
      	</ul>
      	</div>

      </div>

      <div class="row">
        <h3>Abstract</h3>
        <p style="text-align: justify;">
        We address the problem of upsampling a low-resolution (LR) depth map using a registered high-resolution (HR) color image of the same scene. Previous methods based on convolutional neural networks (CNNs) combine nonlinear activations of spatially-invariant kernels to estimate structural details from LR depth and HR color images, and regress upsampling results directly from the networks. In this paper, we revisit the weighted averaging process that has been widely used to transfer structural details from hand-crafted visual features to LR depth maps. We instead learn explicitly sparse and spatially-variant kernels for this task. To this end, we propose a CNN architecture and its efficient implementation, called the deformable kernel network (DKN), that outputs sparse sets of neighbors and the corresponding weights adaptively for each pixel. We also propose a fast version of DKN (FDKN) that runs about 17 times faster (0.01 seconds for a HR image of size 640 × 480). Experimental results on standard benchmarks demonstrate the effectiveness of our approach. In particular, we show that the weighted averaging process with 3 × 3 kernels (i.e., aggregating 9 samples sparsely chosen) outperforms the state of the art by a significant margin.  
        </p>
      </div>
      <div class="row">
      	<h3>Overview of our architecture</h3>
      	<center>
        <img src="./images/arch.png" style="max-width:90%;">
      	</center>
      </div>

      <div class="row">
        <h3>Results</h3>
      </div>

      <div class="row">
        <h3>Paper</h3>
	<p>
     </p><table>
  <tbody><tr></tr>
  <tr><td>
    <a href=""><img style="box-shadow: 5px 5px 2px #888888; margin: 10px" src="./images/dkn.png" width="150px"></a>
  </td>
  <td></td>
  <td>
    B. Kim, J. Ponce, B. Ham<br>
    <b>Deformable kernel networks for guided depth map upsampling</b> <br>
    [<a href="">Paper</a>] [<a href="">Code</a>]
</td></tr></tbody></table>
     
      <!-- <h3>BibTeX</h3>
     <pre><tt></tt></pre> -->

      </div>

      
      
      <div class="row">
        <h3>Acknowledgements</h3>
        <p>
        TBD
        
		</p>
      </div>

    </div>
